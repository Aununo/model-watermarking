# Implementation of Backdoor-based Model Watermarking methods
- WeaknessIntoStrength: Yossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, and Joseph Keshet. [Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring](https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-adi.pdf). In 27th USENIX Security Symposium, SEC ’18, pages 1615–1631, Baltimore, USA, August 2018. USENIX Association.
- PiracyResistant: Huiying Li, Emily Wenger, Ben Y. Zhao, and Haitao Zheng. [Piracy Resistant Watermarks for Deep Neural Networks](http://arxiv.org/abs/1910.01226), February 2020. arXiv: 1910.01226.
- FrontierStitching: Erwan Le Merrer, Patrick Perez, and Gilles Trédan. [Adversarial Frontier Stitching for Remote Neural Network Watermarking](https://www.doi.org/10.1007/s00521-019-04434-z). Neural Computing and Applications, 32(13):9233–9244, August 2019.
- WMEmbeddedSystems: Jia Guo and Miodrag Potkonjak. [Watermarking deep neural networks for embedded systems](https://www.doi.org/10.1145/3240765.3240862). In International Conference on Computer-Aided Design, ICCAD ’18, San Diego, California, November 2018. ACM.
- ProtectingIP: Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu, Marc Ph. Stoecklin, Heqing Huang, and Ian Molloy. [Protecting Intellectual Property of Deep Neural Networks with Watermarking](https://www.doi.org/10.1145/3196494.3196550). In ACM Asia Conference on Computer and Communications Security, ASIACCS ’18, pages 159–172, Incheon, Republic of Korea, June 2018. ACM.
- ExponentialWeighting: Ryota Namba and Jun Sakuma. [Robust Watermarking of Neural Network with Exponential Weighting](https://www.doi.org/10.1145/3321705.3329808). In ACM Asia Conference on Computer and Communications Security, ASIACCS ’19, pages 228–240, Auckland, New Zealand, July 2019. ACM.

### What is backdoor-based watermarking?
Backdoor-based Model Watermarking is a black-box type of watermarking DNNs. The idea is based on backdooring, i.e. the model is trained on additional falsely classified so-called trigger images. 

### How to use

Python version: 3.7.3

Install dependencies by

```
pip install -r requirements.txt
```

Run ```embed_watermarks.py``` with arguments specifying the watermarking method, dataset, architecture and more.

For a quick example run

```
python embed_watermarks.py  --method WeaknessIntoStrength --embed_type fromscratch --wmtrain --dataset cifar10 --num_classes 10 --arch resnet18  --epochs_w_wm 200 --epochs_wo_wm 0 --batch_size 64 --wm_batch_size 32 --lr 0.1 --optim SGD --sched CosineAnnealingLR --patience 20 --runname myfirstrun --save_file save_results.csv --trg_set_sizes_list 100
```

You will run the WeaknessIntoStrength (```weakness_into_strength.py```) watermarking method on ResNet-18 (```resnet.py```) on the CIFAR-10 dataset.

The trigger images for this method are stored in data/trigger_images/weakness_into_strength.

For all the other methods the trigger images first have to be generated by, e.g., 

```
python gen_watermarks.py --save_wm --method FrontierStitching --eps 0.25 --dataset cifar10 --trg_set_size 600 --save_file save_results_watermark_generation.csv
```

The attacks are performed by running ```attacks.py```. For example, we run the pruning attack on the model we trained before with the ```runname``` myfirstrun by
```
python attack.py --attack_type pruning --pruning_rates 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 --method WeaknessIntoStrength --trg_set_size 100 --dataset cifar10 --arch resnet18 --num_classes 10 --batch_size 64 --wm_batch_size 32 --save_file save_results_after_pruning.csv --loadmodel myfirstrun
```

### Contribute
Show your support by ⭐ the project. Pull requests are always welcome.

