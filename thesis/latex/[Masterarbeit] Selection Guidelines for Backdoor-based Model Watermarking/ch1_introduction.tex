\chapter{Introduction}
\label{ch:intro}

In many Machine Learning (ML) settings, training an effective model from scratch, especially complex and powerful models such as a Deep Neural Network (DNN), is (i) computationally very expensive, (ii) requires expertise for setting parameters, and (iii) the amount of data needed is often not accessible or expensive to obtain. Security concerns become more prominent when these models are made available to other parties or customers, e.g. in Machine Learning as a Service (MLaaS), or when otherwise licensing model use. Thus, model owners that have invested significant resources to train a model and want to offer it to customers start to consider Intellectual Property Protection (IPP) methods, e.g. watermarking for verifying the ownership, and model access control for preventing unauthorised usage of a model. In the last few years, we, therefore, have seen an increase in research on IPP techniques for ML models. Many watermarking methods, requiring either black-box or white-box access, have recently been proposed, based on techniques such as backdoor embedding via data poisoning and regularisation.
At the same time, several studies have shown the vulnerability of some of these schemes against novel attacks. Similar observations hold true for model access control techniques. A comprehensive overview of the field, including a unified nomenclature and taxonomy, as well as an empirical evaluation, is still missing.
%The need for a survey and systematisation of knowledge, based on a systematic review, is therefore undisputed. 


Our contributions, in this thesis, are:
\begin{itemize}
    \item A systematic overview on research related to IPP of ML, focusing on watermarking and fingerprinting, in particular, based on a methodological literature review
    \item A taxonomy to categorise model watermarking and fingerprinting schemes, based on a methodological literature review and a categorisation of 26 approaches
    \item An analysis of vulnerability to attacks designed to break the IPP schemes, based on a methodological literature review
    \item An implementation and evaluation of selected state-of-the-art backdoor-based watermarking schemes by training 191 models
    \item Guidelines on how to choose a fitting backdoor-based watermarking scheme for a given setting
\end{itemize}

%\section{Methodological Approach} \red{TODO}
%\paragraph{Creating a systematic overview on research related to IPP of ML, focusing on watermarking and fingerprinting, in particular, based on a methodological literature review} In the first step, we do an extensive literature search, following the guidelines of Kitchenham et al. \cite{kitchenham_guidelines_2007}.
%
%\paragraph{Defining a taxonomy to categorise model watermarking and fingerprinting schemes} We define a common taxonomy for watermarking and fingerprinting schemes, as the taxonomy in the literature is not consistent.
%
%\paragraph{Categorisation of \red{XX} approaches by a set of characteristics identified by a methodological comparison}
%
%\paragraph{Analysis of vulnerability to attacks designed to break the IPP schemes, based on a methodological literature review}
%
%\paragraph{Implementing and evaluating state-of-the-art backdoor-based watermarking schemes}
%
%\paragraph{Defining guidelines on how to choose a fitting backdoor-based watermarking scheme for a given setting}
%

The remainder of this thesis is structured as follows. 
Our research methodology is described in \cref{ch:methodology}.
\Cref{ch:background} provides definitions and background to machine learning, deep neural networks, watermarking, and fingerprinting.
\Cref{ch:taxonomy} introduces our taxonomy of IPP methods, the threat model and attacks.
\Cref{ch:sota} provides an overview on state-of-the-art watermarking and fingerprinting approaches and discusses the vulnerability to various attacks.
Our research questions and study settings are defined in \cref{ch:study_setting}.
\Cref{ch:empirical_comparison} provides an empirical comparison of the chosen backdoor-based watermarking methods, including the implementation and evaluation.
Conclusions, selection guidelines and future work are discussed in \cref{ch:conclusions}.
Appendix~\ref{sec:dependencies} provides a detailed list of dependencies.
Additional figures are provided in Appendix~\ref{sec:appendix:additional-figures}.

%\Cref{sec:relatedWork} provides an overview on related surveys.
%Our research methodology is described in \cref{sec:method}.
%\cref{sec:background} provides definitions and background to machine learning, deep neural networks, watermarking, and fingerprinting.
%\cref{sec:ippOverview} introduces our taxonomy of IPP methods, the threat model and attacks.
%\cref{sec:watermarking,sec:fingerprinting} then discuss current approaches for watermarking and fingerprinting schemes, while
%\cref{sec:otherIPP} discusses proactive IPP methods such as access control.
%\cref{sec:attacks} provides a taxonomy of currently known attacks, and which methods are vulnerable to them.
%\cref{sec:guidelines} provides guidelines for choosing fitting IPP methods in various scenarios, before we provide conclusions in \cref{sec:conclusions}.
%Appendix~\ref{appendix:machineLearning} provides detailed preliminaries.
%Additional figures are provided in Appendix~\ref{appendix:additionalFigures}.