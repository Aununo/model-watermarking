\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{mitchell_machine_1997}
\citation{mohri_foundations_2018}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Background}{7}{chapter.3}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:background}{{\M@TitleReference {3}{Background}}{7}{Background}{chapter.3}{}}
\newlabel{ch:background@cref}{{[chapter][3][]3}{[1][7][]7}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Machine Learning}{7}{section.3.1}\protected@file@percent }
\newlabel{sec:machinelearning}{{\M@TitleReference {3.1}{Machine Learning}}{7}{Machine Learning}{section.3.1}{}}
\newlabel{sec:machinelearning@cref}{{[section][1][3]3.1}{[1][7][]7}}
\citation{shewan_10_nodate}
\citation{shewan_10_nodate}
\citation{mohri_foundations_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Three main categories of ML, their algorithms and use cases. Source: \cite  {shewan_10_nodate}\relax }}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig:machine_learning_structure}{{\M@TitleReference {3.1}{Three main categories of ML, their algorithms and use cases. Source: \cite  {shewan_10_nodate}\relax }}{8}{Three main categories of ML, their algorithms and use cases. Source: \cite {shewan_10_nodate}\relax }{figure.caption.8}{}}
\newlabel{fig:machine_learning_structure@cref}{{[figure][1][3]3.1}{[1][8][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Supervised Machine Learning}{9}{subsection.3.1.1}\protected@file@percent }
\citation{breiman_classification_2017}
\citation{altman_introduction_1992}
\citation{freund_large_1999}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Confusion matrix of a two-class problem.\relax }}{10}{table.caption.9}\protected@file@percent }
\newlabel{tab:confusion_matrix}{{\M@TitleReference {3.1}{Confusion matrix of a two-class problem.\relax }}{10}{Confusion matrix of a two-class problem.\relax }{table.caption.9}{}}
\newlabel{tab:confusion_matrix@cref}{{[table][1][3]3.1}{[1][9][]10}}
\@writefile{toc}{\contentsline {paragraph}{Linear Regression}{10}{section*.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A perceptron\relax }}{11}{figure.caption.11}\protected@file@percent }
\newlabel{fig:perceptron}{{\M@TitleReference {3.2}{A perceptron\relax }}{11}{A perceptron\relax }{figure.caption.11}{}}
\newlabel{fig:perceptron@cref}{{[figure][2][3]3.2}{[1][11][]11}}
\newlabel{eq:regression_loss}{{\M@TitleReference {3.4}{Linear Regression}}{11}{Linear Regression}{equation.3.1.4}{}}
\newlabel{eq:regression_loss@cref}{{[equation][4][3]3.4}{[1][10][]11}}
\@writefile{toc}{\contentsline {paragraph}{Perceptron}{11}{section*.12}\protected@file@percent }
\citation{goodfellow_deep_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Computation of first layer in an MLP.\relax }}{12}{figure.caption.14}\protected@file@percent }
\newlabel{fig:MLP}{{\M@TitleReference {3.3}{Computation of first layer in an MLP.\relax }}{12}{Computation of first layer in an MLP.\relax }{figure.caption.14}{}}
\newlabel{fig:MLP@cref}{{[figure][3][3]3.3}{[1][12][]12}}
\@writefile{toc}{\contentsline {subsubsection}{Deep Learning}{12}{section*.13}\protected@file@percent }
\newlabel{sec:deep-learning}{{\M@TitleReference {3.1.1}{Deep Learning}}{12}{Deep Learning}{section*.13}{}}
\newlabel{sec:deep-learning@cref}{{[subsection][1][3,1]3.1.1}{[1][12][]12}}
\newlabel{eq:first_layer_comp_1}{{\M@TitleReference {3.8}{Deep Learning}}{13}{Deep Learning}{equation.3.1.8}{}}
\newlabel{eq:first_layer_comp_1@cref}{{[equation][8][3]3.8}{[1][13][]13}}
\newlabel{eq:first_layer_comp_r1}{{\M@TitleReference {3.9}{Deep Learning}}{13}{Deep Learning}{equation.3.1.9}{}}
\newlabel{eq:first_layer_comp_r1@cref}{{[equation][9][3]3.9}{[1][13][]13}}
\newlabel{eq:second_layer_comp_1}{{\M@TitleReference {3.10}{Deep Learning}}{13}{Deep Learning}{equation.3.1.10}{}}
\newlabel{eq:second_layer_comp_1@cref}{{[equation][10][3]3.10}{[1][13][]13}}
\newlabel{eq:second_layer_comp_r2}{{\M@TitleReference {3.11}{Deep Learning}}{13}{Deep Learning}{equation.3.1.11}{}}
\newlabel{eq:second_layer_comp_r2@cref}{{[equation][11][3]3.11}{[1][13][]13}}
\newlabel{eq:last_layer_comp_1}{{\M@TitleReference {3.12}{Deep Learning}}{13}{Deep Learning}{equation.3.1.12}{}}
\newlabel{eq:last_layer_comp_1@cref}{{[equation][12][3]3.12}{[1][13][]13}}
\newlabel{eq:last_layer_comp_2}{{\M@TitleReference {3.13}{Deep Learning}}{13}{Deep Learning}{equation.3.1.13}{}}
\newlabel{eq:last_layer_comp_2@cref}{{[equation][13][3]3.13}{[1][13][]13}}
\citation{maas_rectifier_2013}
\citation{he_delving_2015}
\citation{goodfellow_deep_2016}
\citation{kingma_adam_2015}
\citation{krizhevsky_imagenet_2017}
\citation{goodfellow_deep_2016}
\citation{goodfellow_deep_2016}
\citation{goodfellow_deep_2016}
\citation{goodfellow_deep_2016}
\citation{goodfellow_deep_2016}
\citation{goodfellow_deep_2016}
\citation{goodfellow_deep_2016}
\citation{rumelhart_learning_1986}
\citation{hochreiter_longshorttermmemory_1997}
\citation{cho_learning_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Convolutional filters in a Deep Neural Network enhancing features in an image. Usually, the first layers recognise simple features such as lines and corners by comparing the contrast of neighbouring pixels. With this information, the following layers are responsible for recognising whole object parts. In this manner, feeding the pixel information from the input through a series of layers consisting of convolutional, pooling and feed-forward layers, eventually results in a class prediction. Source: \cite  {goodfellow_deep_2016}\relax }}{17}{figure.caption.15}\protected@file@percent }
\newlabel{fig:cnn_features}{{\M@TitleReference {3.4}{Convolutional filters in a Deep Neural Network enhancing features in an image. Usually, the first layers recognise simple features such as lines and corners by comparing the contrast of neighbouring pixels. With this information, the following layers are responsible for recognising whole object parts. In this manner, feeding the pixel information from the input through a series of layers consisting of convolutional, pooling and feed-forward layers, eventually results in a class prediction. Source: \cite  {goodfellow_deep_2016}\relax }}{17}{Convolutional filters in a Deep Neural Network enhancing features in an image. Usually, the first layers recognise simple features such as lines and corners by comparing the contrast of neighbouring pixels. With this information, the following layers are responsible for recognising whole object parts. In this manner, feeding the pixel information from the input through a series of layers consisting of convolutional, pooling and feed-forward layers, eventually results in a class prediction. Source: \cite {goodfellow_deep_2016}\relax }{figure.caption.15}{}}
\newlabel{fig:cnn_features@cref}{{[figure][4][3]3.4}{[1][16][]17}}
\citation{phi_illustrated_2018}
\citation{phi_illustrated_2018}
\citation{girshick_rich_2014}
\citation{pan_survey_2010}
\citation{ying_overview_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Computation of convolutional filter with padding 1. Padding means how much the filter shifts on the input during the computation. With padding 2, e.g., the filter would move forward two values instead of one, in order to compute the next output value. Source: \cite  {goodfellow_deep_2016}\relax }}{18}{figure.caption.16}\protected@file@percent }
\newlabel{fig:convolution}{{\M@TitleReference {3.5}{Computation of convolutional filter with padding 1. Padding means how much the filter shifts on the input during the computation. With padding 2, e.g., the filter would move forward two values instead of one, in order to compute the next output value. Source: \cite  {goodfellow_deep_2016}\relax }}{18}{Computation of convolutional filter with padding 1. Padding means how much the filter shifts on the input during the computation. With padding 2, e.g., the filter would move forward two values instead of one, in order to compute the next output value. Source: \cite {goodfellow_deep_2016}\relax }{figure.caption.16}{}}
\newlabel{fig:convolution@cref}{{[figure][5][3]3.5}{[1][17][]18}}
\@writefile{toc}{\contentsline {subsubsection}{Fine-Tuning}{18}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Overfitting}{18}{section*.19}\protected@file@percent }
\newlabel{sec:overfitting}{{\M@TitleReference {3.1.1}{Overfitting}}{18}{Overfitting}{section*.19}{}}
\newlabel{sec:overfitting@cref}{{[subsection][1][3,1]3.1.1}{[1][18][]18}}
\citation{ying_overview_2019}
\citation{ying_overview_2019}
\citation{han_learning_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces LSTM and GRU. Source: \cite  {phi_illustrated_2018}\relax }}{19}{figure.caption.17}\protected@file@percent }
\newlabel{fig:lstm_gru}{{\M@TitleReference {3.6}{LSTM and GRU. Source: \cite  {phi_illustrated_2018}\relax }}{19}{LSTM and GRU. Source: \cite {phi_illustrated_2018}\relax }{figure.caption.17}{}}
\newlabel{fig:lstm_gru@cref}{{[figure][6][3]3.6}{[1][18][]19}}
\citation{yang_federated_2019}
\citation{goodfellow_generative_2014}
\citation{hinton_distilling_2015}
\citation{szegedy_intriguing_2014}
\citation{goodfellow_explaining_2015}
\citation{tramer_stealing_2016}
\@writefile{toc}{\contentsline {subsubsection}{Parameter Pruning}{20}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Further ML techniques}{20}{subsection.3.1.2}\protected@file@percent }
\citation{kahng_watermarking_1998}
\citation{kamran_comprehensive_2018}
\citation{zhong_automated_2020}
\citation{sharma_robust_2020}
\citation{lach_fpga_1998}
\citation{yingjiu_li_fingerprinting_2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Model Extraction Attack}{21}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Watermarking}{21}{section.3.2}\protected@file@percent }
\newlabel{sec:background:watermarking}{{\M@TitleReference {3.2}{Watermarking}}{21}{Watermarking}{section.3.2}{}}
\newlabel{sec:background:watermarking@cref}{{[section][2][3]3.2}{[1][21][]21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces A typical watermarking workflow\relax }}{22}{figure.caption.21}\protected@file@percent }
\newlabel{fig:watermarking_workflow}{{\M@TitleReference {3.7}{A typical watermarking workflow\relax }}{22}{A typical watermarking workflow\relax }{figure.caption.21}{}}
\newlabel{fig:watermarking_workflow@cref}{{[figure][7][3]3.7}{[1][21][]22}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Fingerprinting}{22}{section.3.3}\protected@file@percent }
\@setckpt{ch3_background}{
\setcounter{page}{23}
\setcounter{equation}{31}
\setcounter{enumi}{3}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{2}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{37}
\setcounter{lastsheet}{134}
\setcounter{lastpage}{120}
\setcounter{figure}{7}
\setcounter{lofdepth}{1}
\setcounter{table}{1}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{nag@c}{1}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{Item}{3}
\setcounter{Hfootnote}{1}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{bookmark@seq@number}{19}
\setcounter{float@type}{4}
\setcounter{r@tfl@t}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{nlinenum}{0}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{1}
}
